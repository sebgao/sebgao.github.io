<!DOCTYPE html>
<html>
<title>Training ImageNet using PyTorch, step by step</title>

<xmp  theme="journal" style="display:none;">
###

The note serves as my reminder for later day review. But you can think that this is a preliminary note for training ResNet-50 on the ImageNet from scratch using PyTorch.

### Introduction

Nowadays, deep learning gets remarkable result in image classification, sentimental analysis and etc.
There are several deep learning frameworks developing for research or industry engineering. PyTorch is a productive and flexible framework for deep learning, especially for the research purpose. PyTorch provides a variety of pretrained models, including VGG, ResNet series, etc. You should have heard of that these models are trained on the ImageNet dataset, more specifically, the ILSVRC (ImageNet Large Scale Visual Recognition Competition) dataset for classification.

The ILSVRC dataset has many versions, being updated from 2012 to 2017 annually. And moreover, this dataset is not meant just for the classification task. Object detection is also a challenge out of classification. But as for us, the ImageNet dataset refers to the 1k-classification subset of the ILSVRC dataset unless stated otherwise. The 1k-classification dataset is fixed throughout years, so you don't have to mind which year the dataset is updated.

Basically, the ImageNet has 1000 categories of visual objects, a little bit fine-grained, and 1300 images per category. Some categories, "lynx", "leopard" and "jaguar", are even hard to tell apart for those who do not often go to the zoo, ...maybe.
Training ConvNets on the ImageNet isn't a thing like training one on MNIST or CIFAR-10 (somewhat, "toy" datasets, IMO). Here comes natural photo resolution and so many categories within ImageNet. It's hard to tackle, but not hardest (since there is a 21K-classification version of ImageNet). And more engineering tricks are needed here.

So let's delve into the hard part.

### Data Preparation

The ImageNet dataset itself is ~162G big. You should, however, have a disk with __300G__+ availiable space to download and extract the ImageNet from compressed format. __SSD__s are recommended because of their faster speed (which we'll review later). Downloading it straightly from the ImageNet official site can be annoying, which needs mail verification and access approval. For me, the request is not approved yet upon the minute this sentence being written. But luckily, the dataset is also availiable on [Kaggle ImageNet Challenge](https://www.kaggle.com/c/imagenet-object-localization-challenge) or [Academic Torrents](http://academictorrents.com/details/a306397ccf9c2ead27155983c254227c0fd938e2). Typically it will take a whole day to download the dataset for users whose internet bandwidth is ~3MiB/s. To whom downloads it from Kaggle in China, there will be some accidental interruptions. We can enable resume for the break point in Linux by `wget -c "URL"`.
 
</xmp>

<script src="../v/0.2/strapdown.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</html>